{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b27b19b",
   "metadata": {
    "id": "2b27b19b"
   },
   "source": [
    "# Applied Analytics Portfolio\n",
    "\n",
    "**Predicting and Explaining Healthcare App Quality**\n",
    "\n",
    "Group: `___`\n",
    "\n",
    "Names & Student IDs: `___`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1bb21",
   "metadata": {
    "id": "9ff1bb21"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Briefly describe the **decision context**:\n",
    "\n",
    "- Mental health unit that wants to recommend high-quality healthcare apps.\n",
    "- Patients have a range of mental illnesses and somatic comorbidities.\n",
    "\n",
    "Explain **why prediction helps** and what the **overall goal** of this portfolio is:\n",
    "\n",
    "- Use app metadata and user reviews to estimate whether an app is likely to be highly rated.\n",
    "- Identify key factors that drive user-perceived app quality.\n",
    "\n",
    "Conclude with a short **structure overview** of the notebook/report (what is done in Sections 2–5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775cfac",
   "metadata": {
    "id": "e775cfac"
   },
   "source": [
    "## 2. Data Understanding and Preparation\n",
    "\n",
    "### 2.1 Research Goal and Operationalization\n",
    "- Formulate a **precise prediction question**.\n",
    "- Define what **\"high-quality\" / \"highly rated\"** means (e.g., rating threshold + minimum number of ratings).\n",
    "- Specify which apps you will include (e.g., which categories, filters).\n",
    "\n",
    "### 2.2 Data Overview\n",
    "- Number of apps and reviews after filtering.\n",
    "- Brief description of key variables (metadata and text).\n",
    "\n",
    "### 2.3 Cleaning and Filtering\n",
    "- Handle outliers (e.g., extreme prices, extremely low number of ratings).\n",
    "- Check missing values in important variables and decide on imputation vs. dropping.\n",
    "- Document inclusion criteria and any comparator groups (e.g., medical vs. non-medical apps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0cfbbd",
   "metadata": {
    "id": "ac0cfbbd"
   },
   "outputs": [],
   "source": [
    "# 2. Data Understanding and Preparation\n",
    "# TODO: Load your datasets here and perform basic checks\n",
    "import pandas as pd\n",
    "\n",
    "# Example:\n",
    "# apps = pd.read_csv('apps.csv')\n",
    "# reviews = pd.read_csv('reviews.csv')\n",
    "# apps.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917c936",
   "metadata": {
    "id": "4917c936"
   },
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "- Explore distributions of ratings, number of ratings, prices, categories, etc.\n",
    "- Visualize relevant relationships (e.g., rating vs. price, rating vs. category).\n",
    "- Use basic text mining on reviews: word frequencies, simple sentiment or topic structure.\n",
    "- Create and justify **new features** that may help prediction (e.g., sentiment score, review length, price bins).\n",
    "- Comment on what these patterns suggest about app quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb17c1",
   "metadata": {
    "id": "5bdb17c1"
   },
   "outputs": [],
   "source": [
    "# 3. Data Exploration\n",
    "# TODO: EDA plots and feature creation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example placeholder:\n",
    "# apps['log_ratings'] = np.log1p(apps['ratingCount'])\n",
    "# apps['averageRating'].hist()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9203dc",
   "metadata": {
    "id": "1d9203dc"
   },
   "source": [
    "## 4. Modeling Approach\n",
    "\n",
    "### 4.1 Review Sentiment with Zero-/Few-Shot Learning (SetFit or alternative)\n",
    "\n",
    "1. Define sentiment classes (e.g., positive / neutral / negative).\n",
    "2. Manually label a small, balanced subset of reviews.\n",
    "3. Fine-tune a SetFit model or a LLM model and evaluate performance.\n",
    "5. Aggregate predicted sentiment to the **app level** (e.g., share of positive reviews).\n",
    "\n",
    "These aggregated sentiment metrics will be used as features in Section 4.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bdcb172",
   "metadata": {
    "id": "1bdcb172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setfit in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: sentence-transformers>=3 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from sentence-transformers[train]>=3->setfit) (5.2.0)\n",
      "Requirement already satisfied: transformers>=4.41.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from setfit) (4.57.3)\n",
      "Requirement already satisfied: evaluate>=0.3.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from setfit) (0.4.6)\n",
      "Requirement already satisfied: huggingface_hub>=0.24.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from setfit) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from setfit) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (2.3.5)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from huggingface_hub>=0.24.0->setfit) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.9.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from transformers>=4.41.0->setfit) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from transformers>=4.41.0->setfit) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from transformers>=4.41.0->setfit) (0.7.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from sentence-transformers[train]>=3->setfit) (1.12.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cbogo\\anaconda3\\envs\\appliedanalytics\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Installieren der benötigten Bibliotheken für das SetFit Modell\n",
    "!pip install setfit datasets tqdm pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040e7067-1716-4d9d-bdcc-4fcacf29a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Lade das NEUE Dataset...\n",
      "--> Super! Neue Felder 'price_eur' und 'privacy' gefunden.\n",
      "--> Apps geladen: 46324\n",
      "--> Reviews geladen: 443942\n",
      "--> Datenvorbereitung abgeschlossen (mit neuen Feldern).\n",
      "\n",
      "2. Trainiere Sentiment-Modell (Few-Shot Learning)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "C:\\Users\\cbogo\\AppData\\Local\\Temp\\ipykernel_20660\\2750418815.py:94: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53458de032846b19b668e741493710f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cbogo\\AppData\\Local\\Temp\\ipykernel_20660\\2750418815.py:101: DeprecationWarning: `SetFitTrainer.train` does not accept keyword arguments anymore. Please provide training arguments via a `TrainingArguments` instance to the `SetFitTrainer` initialisation or the `SetFitTrainer.train` method.\n",
      "  trainer.train(batch_size=4, epochs=1)\n",
      "***** Running training *****\n",
      "  Num unique pairs = 640\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "C:\\Users\\cbogo\\anaconda3\\envs\\AppliedAnalytics\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training abgeschlossen.\n",
      "\n",
      "3. Starte Analyse der echten Reviews...\n",
      "--> Analysiere 30524 Reviews (Top 10 pro App)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846e8c396121494bac406490c726e8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KI-Analyse läuft:   0%|          | 0/3816 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Berechne Scores pro App...\n",
      "----------------------------------------\n",
      "FERTIG! Sektion 4.1 erledigt.\n",
      "----------------------------------------\n",
      "                                            app_name  review_count  \\\n",
      "0         NCLEX-RN tests - practice exam preparation             0   \n",
      "1                                    Studio360 Cycle             0   \n",
      "2                                      Smoke Finance             0   \n",
      "3                               Women's Golf Network             0   \n",
      "4  White Noise - Natural Calm Sounds for Sleep Cycle             1   \n",
      "5   Army Fitness Workout Exercises & APFT Calculator             0   \n",
      "6                                     Champs Fitness             0   \n",
      "7                          Betsy's Health Foods Inc.             0   \n",
      "8                                   VT1 Martial Arts             0   \n",
      "9                                  REDCap Mobile App             0   \n",
      "\n",
      "   share_positive  share_negative  \n",
      "0             0.5             0.5  \n",
      "1             0.5             0.5  \n",
      "2             0.5             0.5  \n",
      "3             0.5             0.5  \n",
      "4             1.0             0.0  \n",
      "5             0.5             0.5  \n",
      "6             0.5             0.5  \n",
      "7             0.5             0.5  \n",
      "8             0.5             0.5  \n",
      "9             0.5             0.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from datasets import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "# --- KONFIGURATION: PFADE ANPASSEN ---\n",
    "# Bitte hier euren Pfad zu den CSV-Dateien eintragen\n",
    "# (Hier sind Cems Pfade als Platzhalter)\n",
    "PATH_APPS = r'C:/Users/cbogo/Downloads/apple_apps_medizin.csv'\n",
    "PATH_REVIEWS = r'C:/Users/cbogo/Downloads/app_reviews_medizin.csv'\n",
    "\n",
    "# ==========================================\n",
    "# SCHRITT 1: DATEN LADEN & VORBEREITEN\n",
    "# ==========================================\n",
    "# BITTE HIER DIE NEUEN DATEINAMEN EINTRAGEN\n",
    "PATH_APPS_NEW = r'C:/Users/cbogo/Downloads/apple_apps_medizin_1.csv' # <-- Anpassen!\n",
    "PATH_REVIEWS_NEW = r'C:/Users/cbogo/Downloads/app_reviews_medizin_1.csv' # <-- Anpassen!\n",
    "\n",
    "print(\"1. Lade das NEUE Dataset...\")\n",
    "try:\n",
    "    apps_df = pd.read_csv(PATH_APPS_NEW, low_memory=False)\n",
    "    reviews_df = pd.read_csv(PATH_REVIEWS_NEW, low_memory=False)\n",
    "    \n",
    "    # Check: Haben wir die neuen Spalten wirklich?\n",
    "    if 'price_eur' in apps_df.columns and 'privacy_not_collected_bool' in apps_df.columns:\n",
    "        print(\"--> Super! Neue Felder 'price_eur' und 'privacy' gefunden.\")\n",
    "    else:\n",
    "        print(\"WARNUNG: Neue Felder nicht gefunden. Hast du die richtige Datei geladen?\")\n",
    "\n",
    "    # Wir arbeiten weiter mit einer Kopie\n",
    "    filtered_apps = apps_df.copy()\n",
    "\n",
    "    # --- UMWANDLUNG DER NEUEN FELDER ---\n",
    "    \n",
    "    # 1. Preis: Wir nehmen direkt 'price_eur' (keine eigene Reinigung mehr nötig!)\n",
    "    # Falls mal ein Wert fehlt, nehmen wir 0.0 an\n",
    "    filtered_apps['price_numeric'] = pd.to_numeric(filtered_apps['price_eur'], errors='coerce').fillna(0.0)\n",
    "\n",
    "    # 2. Review Count sicherstellen (Text zu Zahl)\n",
    "    filtered_apps['review_count'] = pd.to_numeric(filtered_apps['review_count'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # 3. Privacy für später vorbereiten (Bool zu Zahl: True=1, False=0)\n",
    "    # Das brauchen wir gleich für Sektion 4.2\n",
    "    filtered_apps['privacy_flag'] = filtered_apps['privacy_not_collected_bool'].astype(int)\n",
    "\n",
    "    print(f\"--> Apps geladen: {len(filtered_apps)}\")\n",
    "    print(f\"--> Reviews geladen: {len(reviews_df)}\")\n",
    "    print(\"--> Datenvorbereitung abgeschlossen (mit neuen Feldern).\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"FEHLER: Die neuen Dateien wurden nicht gefunden. Bitte Pfad prüfen!\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHRITT 2: MODELL TRAINING (FEW-SHOT)\n",
    "# ==========================================\n",
    "print(\"\\n2. Trainiere Sentiment-Modell (Few-Shot Learning)...\")\n",
    "\n",
    "# Wir nutzen ein manuell erstelltes, perfekt balanciertes Set (8 Positiv / 8 Negativ)\n",
    "# Dies verhindert Bias, da zufällige Reviews oft zu 90% positiv sind.\n",
    "training_data = {\n",
    "    \"text\": [\n",
    "        # POSITIV (Label 1)\n",
    "        \"Die App hilft mir sehr gut, meine Medikamente zu managen.\",\n",
    "        \"Endlich eine Übersicht, die einfach zu bedienen ist. Super!\",\n",
    "        \"Tolle Funktionen und sehr übersichtlich gestaltet.\",\n",
    "        \"Der Symptom-Tracker ist genau das, was ich gesucht habe.\",\n",
    "        \"Sehr hilfreich im Alltag mit meiner Krankheit.\",\n",
    "        \"Schnelle Ladezeiten und stürzt nie ab. Perfekt.\",\n",
    "        \"Ich fühle mich durch die App viel sicherer.\",\n",
    "        \"Klasse Support und regelmäßige Updates.\",\n",
    "        # NEGATIV (Label 0)\n",
    "        \"Die App stürzt ständig ab, völlig unbrauchbar.\",\n",
    "        \"Viel zu teuer für das, was geboten wird.\",\n",
    "        \"Datenschutz ist hier eine Katastrophe. Nie wieder.\",\n",
    "        \"Funktioniert nach dem Update überhaupt nicht mehr.\",\n",
    "        \"Werbung nervt total und macht die Nutzung unmöglich.\",\n",
    "        \"Unübersichtlich und kompliziert. Ich lösche sie wieder.\",\n",
    "        \"Die Verbindung zum Server bricht andauernd ab.\",\n",
    "        \"Leider keine Hilfe, reine Zeitverschwendung.\"\n",
    "    ],\n",
    "    \"label\": [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "# Dataset erstellen\n",
    "train_dataset = Dataset.from_dict(training_data)\n",
    "\n",
    "# Modell laden (Multilingual für Deutsch/Englisch)\n",
    "model_id = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "model = SetFitModel.from_pretrained(model_id, device=\"cpu\") # CPU erzwingen für Kompatibilität\n",
    "\n",
    "# Trainer initialisieren\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    metric=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Training starten (Dauert ca. 1-2 Minuten)\n",
    "trainer.train(batch_size=4, epochs=1)\n",
    "print(\"--> Training abgeschlossen.\")\n",
    "\n",
    "# ==========================================\n",
    "# SCHRITT 3: INFERENZ (ANWENDUNG AUF ECHTE DATEN)\n",
    "# ==========================================\n",
    "print(\"\\n3. Starte Analyse der echten Reviews...\")\n",
    "\n",
    "# Nur Reviews der relevanten Apps nehmen\n",
    "valid_ids = filtered_apps['app_id'].unique()\n",
    "reviews_analysis = reviews_df[reviews_df['app_id'].isin(valid_ids)].copy()\n",
    "reviews_analysis = reviews_analysis.dropna(subset=['review'])\n",
    "\n",
    "# PERFORMANCE OPTIMIERUNG:\n",
    "# Wir nehmen nur die neuesten 10 Reviews pro App.\n",
    "# Grund: Analyse von allen 70k Reviews würde auf CPU >10 Stunden dauern.\n",
    "# 10 Reviews reichen für einen statistischen Trend.\n",
    "reviews_analysis = reviews_analysis.groupby('app_id').head(10)\n",
    "\n",
    "print(f\"--> Analysiere {len(reviews_analysis)} Reviews (Top 10 pro App)...\")\n",
    "\n",
    "# Vorhersage in Batches (Häppchenweise) mit Ladebalken\n",
    "texts = reviews_analysis[\"review\"].tolist()\n",
    "results = []\n",
    "batch_size = 8\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"KI-Analyse läuft\"):\n",
    "    batch = texts[i : i + batch_size]\n",
    "    preds = model.predict(batch)\n",
    "    results.extend(preds.tolist())\n",
    "\n",
    "reviews_analysis[\"ai_sentiment\"] = results\n",
    "\n",
    "# ==========================================\n",
    "# SCHRITT 4: AGGREGATION & FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "print(\"\\n4. Berechne Scores pro App...\")\n",
    "\n",
    "# Durchschnitt berechnen (1=Positiv, 0=Negativ)\n",
    "app_stats = reviews_analysis.groupby('app_id')['ai_sentiment'].agg(['mean', 'count']).reset_index()\n",
    "app_stats.columns = ['app_id', 'sentiment_score', 'sentiment_count_ai']\n",
    "\n",
    "# Merge mit der App-Tabelle\n",
    "# (Erst alte Spalten löschen, falls vorhanden, um Fehler bei Mehrfachausführung zu vermeiden)\n",
    "cols_to_drop = ['sentiment_score', 'sentiment_count_ai', 'share_positive', 'share_negative']\n",
    "filtered_apps = filtered_apps.drop(columns=[c for c in cols_to_drop if c in filtered_apps.columns])\n",
    "\n",
    "filtered_apps = filtered_apps.merge(app_stats, on='app_id', how='left')\n",
    "\n",
    "# Fehlende Werte auffüllen (Apps ohne Text-Reviews bekommen Score 0.5 = Neutral)\n",
    "filtered_apps['sentiment_score'] = filtered_apps['sentiment_score'].fillna(0.5)\n",
    "\n",
    "# Die geforderten Features erstellen\n",
    "filtered_apps['share_positive'] = filtered_apps['sentiment_score']       # Identisch mit Score\n",
    "filtered_apps['share_negative'] = 1.0 - filtered_apps['share_positive']  # Der Rest ist negativ\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"FERTIG! Sektion 4.1 erledigt.\")\n",
    "print(\"-\" * 40)\n",
    "print(filtered_apps[['app_name', 'review_count', 'share_positive', 'share_negative']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042a018f-d175-410e-b51d-d34cede6b048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Apps mit '0 Reviews' aber echtem Sentiment: 180\n",
      "\n",
      "Beweis-Stück für App ID 1265836047 (Breathing Box):\n",
      "--> Gefundener Text: 'Voice is very cold and App turns itself off when phone locks'\n",
      "(Daher kommt der Score! Die '0' im Review-Count war falsch.)\n",
      "\n",
      "------------------------------\n",
      "DATEN-QUALITÄT ÜBERSICHT\n",
      "------------------------------\n",
      "Gesamt Apps:              46324\n",
      "Davon mit echten Texten:  5924   (12.8%)\n",
      "Davon aufgefüllt (0.5):   40400 (87.2%)\n"
     ]
    }
   ],
   "source": [
    "# --- QUALITÄTS-CHECK (Sanity Check) ---\n",
    "\n",
    "# 1. Fall \"Geister-Reviews\" untersuchen\n",
    "# Wir suchen Apps, die laut Store 0 Reviews haben, aber laut KI einen Score haben\n",
    "ghost_apps = filtered_apps[\n",
    "    (filtered_apps['review_count'] == 0) & \n",
    "    (filtered_apps['share_positive'] != 0.5) # Ungleich 0.5 heißt: Die KI hat was gefunden!\n",
    "]\n",
    "\n",
    "print(f\"Anzahl Apps mit '0 Reviews' aber echtem Sentiment: {len(ghost_apps)}\")\n",
    "\n",
    "if len(ghost_apps) > 0:\n",
    "    sample_id = ghost_apps.iloc[0]['app_id']\n",
    "    print(f\"\\nBeweis-Stück für App ID {sample_id} ({ghost_apps.iloc[0]['app_name']}):\")\n",
    "    # Wir holen den Text aus der Review-Tabelle\n",
    "    texts = reviews_analysis[reviews_analysis['app_id'] == sample_id]['review'].tolist()\n",
    "    print(f\"--> Gefundener Text: '{texts[0]}'\")\n",
    "    print(\"(Daher kommt der Score! Die '0' im Review-Count war falsch.)\")\n",
    "\n",
    "# 2. Wie viele sind \"echt\" vs. \"aufgefüllt\" (0.5)?\n",
    "total = len(filtered_apps)\n",
    "filled = len(filtered_apps[filtered_apps['share_positive'] == 0.5])\n",
    "real = total - filled\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"DATEN-QUALITÄT ÜBERSICHT\")\n",
    "print(\"-\"*30)\n",
    "print(f\"Gesamt Apps:              {total}\")\n",
    "print(f\"Davon mit echten Texten:  {real}   ({(real/total)*100:.1f}%)\")\n",
    "print(f\"Davon aufgefüllt (0.5):   {filled} ({(filled/total)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90adfa51",
   "metadata": {
    "id": "90adfa51"
   },
   "source": [
    "### 4.2 Predictive Modeling of App Quality\n",
    "\n",
    "1. **Define the target** variable at app level (e.g., high_quality = 1 if avg rating ≥ threshold and sufficient rating count).\n",
    "2. **Model A – Simple & interpretable:** Logistic Regression or a small Decision Tree.\n",
    "3. **Model B – More powerful:** e.g., Random Forest or Gradient Boosting with basic hyperparameter tuning.\n",
    "4. Compare performance (accuracy, precision, recall, F1, ROC-AUC, etc.) and comment on the trade-off between interpretability and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be30d9",
   "metadata": {
    "id": "08be30d9"
   },
   "outputs": [],
   "source": [
    "# 4.2 Predictive Modeling of App Quality\n",
    "# TODO: Build train/test split, fit Model A and Model B, and evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Example placeholder:\n",
    "# X = apps_model_features\n",
    "# y = apps['high_quality']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0c1e2",
   "metadata": {
    "id": "7fa0c1e2"
   },
   "source": [
    "## 5. Interpretation and Argumentation of Results\n",
    "\n",
    "1. **Model Interpretation / Explainable AI**\n",
    "- Inspect and visualize feature importance (e.g., SHAP values or model-specific importances).\n",
    "- Discuss which features most strongly influence predicted app quality.\n",
    "\n",
    "2. **Fairness & Bias Reflection**\n",
    "- Where could sampling bias, measurement error, or missing data affect your results?\n",
    "- Briefly relate your reflections to fairness notions mentioned in the course.\n",
    "\n",
    "3. **LLM / SetFit as Method**\n",
    "- Discuss where these methods might introduce bias or instability.\n",
    "- Mention how sensitive your results are to label definitions or prompts (short reflection).\n",
    "\n",
    "4. **Practical Insights for the Clinic**\n",
    "- List 2–4 concrete, comprehensible recommendations that the mental health unit could use.\n",
    "- Focus on what your results *suggest they should pay attention to* when recommending apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4b4e0",
   "metadata": {
    "id": "91b4b4e0"
   },
   "source": [
    "## 6. AI Tools and References\n",
    "\n",
    "- Briefly describe where AI tools (e.g., ChatGPT, Copilot) were used, in line with FU guidelines.\n",
    "- List key papers, blog posts, or documentation that you relied on for methods.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
